{"cells":[{"cell_type":"markdown","metadata":{"id":"JBglaaUF6Dga"},"source":["## Linear Regression\n","An estimator is any model that tries to estimate a variable y from another variable(s) x given pairs of data (x<sub>1</sub>,y<sub>1</sub>),(x<sub>2</sub>,y<sub>2</sub>),...,(x<sub>N</sub>,y<sub>N</sub>)\n","\n","Regression is when the targets (y) are quantities (not cat vs dog but rather price of a house)\n","\n","An example would be trying to guess how many people will buy icecream from a shop at any day given the temprature on that day. In this case, the target is the number of icecream people will buy, it is an integer and any value (ex: 14 icecreams) doesn't represent a particular class, so it will be represented as a regression problem. In this case, it turns out that x is also a quantity (temprature); however, this is not necessary and is tackled by approaches other than linear regression.\n","\n","To estimate the price of the icecream from temperature we gather the data on various days from various different places and get the following data.\n","\n","\n","\n","We can see that a line (could  also be a curve) could fit the data, but how can we find which line exactly.\n","\n","#### Line Equation Review\n","A line in 2D can be parametrized using a slope m and a y-intercept b which would result in it having an equation\n","\n","$$y = mx+b$$\n","\n","In the example of the icecream, if the temperature at a day was 30, our prediction for the number of icecreams sold would be m\\*30 + b, so we simply need to find m and b.\n","\n","#### Squared Loss\n","We need some measurement of how good our line is to be able to find the \"best\" line, so we will measure the difference between our predictions and the correct values from the data.\n","\n","\n","Then, we will square all the differences and add them up. This will be the value we try to minimize.\n","\n","#### Note\n","The normal equation will probably not work. It is left for you to figure it out and let everyone else know, let's see who figures it out first (it's a tricky issue).\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5H2MP2s6Dgl","executionInfo":{"status":"aborted","timestamp":1662147638771,"user_tz":-120,"elapsed":15,"user":{"displayName":"amin fadel","userId":"07135920196115516185"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EfSmHu0f6Dgn","executionInfo":{"status":"aborted","timestamp":1662147638773,"user_tz":-120,"elapsed":16,"user":{"displayName":"amin fadel","userId":"07135920196115516185"}}},"outputs":[],"source":["class Linear_Regression():\n","    '''\n","    Linear Regression model created using only NumPy\n","    \n","    Attributes\n","    ----------\n","    weights: np.array of floats\n","        All the parameters of the model (including bias)\n","    '''\n","    def __init__(self):\n","        self.weights = None\n","        self.prediction = None\n","        \n","    def train(self,data_X,data_y):\n","        '''\n","        Train the model using the given data\n","        \n","        Parameters\n","        ----------\n","        data_X: np.array, shape = (N, num_features)\n","            Features from the data, each row is one data point. Assumes that a column of ones was added to data_X\n","        data_y: np.array, shape = (N, num_targets)\n","            The target values to predict, each row contains the targets for one data point\n","        '''\n","        ########################## Insert code here ##########################\n","        theta = np.zeros(data_X.shape[1])\n","        iterations = 50000\n","        alpha = 0.0000000069\n","        cost_history = np.zeros(iterations)\n","        for i in range(1):\n","          for i in range(iterations):\n","            predictions = data_X.dot(theta)\n","            errors = np.subtract(predictions, data_y)\n","            sum_delta = (alpha / data_X.shape[0]) * data_X.transpose().dot(errors);\n","            theta = theta - sum_delta;\n","        self.weights = theta\n","    def predict(self,x_to_predict):\n","        '''\n","        Predict using the given value as input\n","        \n","        Assumes that self.train(.,.) has been called before calling this method\n","        \n","        Parameters\n","        ----------\n","        x_to_predict: np.array, shape = (M, num_features)\n","            A given list of inputs to predict targets for, each row is one input. Assumes that a column of ones was added similar to the training data\n","        \n","        Returns\n","        -------\n","        np.array of floats, shape = (M, num_targets)\n","            Predicted values for each input\n","        '''\n","        ########################## Insert code here ##########################\n","        self.prediction = np.dot(x_to_predict,self.weights)\n","        "]},{"cell_type":"markdown","metadata":{"id":"hX6W7_VE6Dgo"},"source":["### Import the data and remove useless columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OjvUmB4M6Dgp","executionInfo":{"status":"aborted","timestamp":1662147638774,"user_tz":-120,"elapsed":17,"user":{"displayName":"amin fadel","userId":"07135920196115516185"}}},"outputs":[],"source":["df = pd.read_csv(\"train.csv\")\n","df.drop(columns=[\"Id\"],inplace=True)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"-U-MG5Sz6Dgq"},"source":["### Handle the missing data (NaNs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gn3fgyPQ6Dgq","executionInfo":{"status":"aborted","timestamp":1662147638775,"user_tz":-120,"elapsed":18,"user":{"displayName":"amin fadel","userId":"07135920196115516185"}}},"outputs":[],"source":["df.drop(columns=df.columns[df.isnull().sum().values>200],inplace=True)\n","df.dropna(inplace=True)\n","df.isnull().sum().values"]},{"cell_type":"markdown","metadata":{"id":"vavWXWdm6Dgr"},"source":["### Replace categorical data (strings) with numerical values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otxtHHZl6Dgs","executionInfo":{"status":"aborted","timestamp":1662147638776,"user_tz":-120,"elapsed":18,"user":{"displayName":"amin fadel","userId":"07135920196115516185"}}},"outputs":[],"source":["obj_to_replace = df[\"MSZoning\"].dtype\n","\n","for column in df.columns:\n","    if df[column].dtype == obj_to_replace:\n","        uniques = np.unique(df[column].values)\n","        for idx,item in enumerate(uniques):\n","            df[column] = df[column].replace(item,idx)\n","            \n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"X-7LW5aW6Dgt"},"source":["### Add the bias column (column of ones)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qytNU91m6Dgu","executionInfo":{"status":"aborted","timestamp":1662147638776,"user_tz":-120,"elapsed":18,"user":{"displayName":"amin fadel","userId":"07135920196115516185"}}},"outputs":[],"source":["df[\"bias\"] = np.ones(df.shape[0])\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"Erg94Y5N6Dgu"},"source":["### Divide the data into training, testing, X, and y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZpNCEjJ_6Dgv","executionInfo":{"status":"aborted","timestamp":1662147638777,"user_tz":-120,"elapsed":18,"user":{"displayName":"amin fadel","userId":"07135920196115516185"}}},"outputs":[],"source":["df = df.sample(frac=1).reset_index(drop=True)\n","training_df = df[:-100]\n","val_df = df[-100:]\n","training_y = training_df[\"SalePrice\"].values\n","training_X = training_df.drop(columns=[\"SalePrice\"]).values\n","val_y = val_df[\"SalePrice\"].values\n","val_X = val_df.drop(columns=[\"SalePrice\"]).values\n","\n","print(training_X.shape)\n","print(np.mean(training_y))\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"H9ncUOzD6Dgw"},"source":["### Train the linear regressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q3EsCcPnKBqH","executionInfo":{"status":"aborted","timestamp":1662147638777,"user_tz":-120,"elapsed":18,"user":{"displayName":"amin fadel","userId":"07135920196115516185"}}},"outputs":[],"source":["# Create and fit the model\n","LR_regressor = Linear_Regression()\n","LR_regressor.train(training_X,training_y)\n","print(LR_regressor.weights)\n","\n","\n","# Calculate Mean Absolute Error (Easier to interpret than MSE)\n","########################## Insert code here ##########################\n","N = 1/training_X.shape[0]\n","total_sum = 0\n","for i in range(training_X.shape[0]):\n","  total_sum += abs(LR_regressor.weights.dot(training_X[i])-training_y[i])\n","error = N*total_sum\n","print(error)"]},{"cell_type":"markdown","metadata":{"id":"U8QTtel66Dgx"},"source":["### Train using the sklearn linear regressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jIZL573s6Dgy","executionInfo":{"status":"aborted","timestamp":1662147638778,"user_tz":-120,"elapsed":19,"user":{"displayName":"amin fadel","userId":"07135920196115516185"}}},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","\n","# Create and fit the model\n","########################## Insert code here ##########################\n","LR_sk = LinearRegression().fit(training_X,training_y)\n","print(LR_sk.coef_)\n","\n","# Calculate Mean Absolute Error (Easier to interpret than MSE)\n","########################## Insert code here ##########################\n","N = 1/training_X.shape[0]\n","total_sum = 0\n","for i in range(training_X.shape[0]):\n","  total_sum += abs(LR_sk.coef_.dot(training_X[i])-training_y[i])\n","error = N*total_sum\n","print(error)"]}],"metadata":{"colab":{"collapsed_sections":["-U-MG5Sz6Dgq","vavWXWdm6Dgr","X-7LW5aW6Dgt"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":0}
